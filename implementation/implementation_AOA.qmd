---
title: "Implementation of aoa.R"
subtitle: "Supplementary to the thesis 'Development of a local data point density approach to assess the Area of Applicability for spatial prediction models'"
author: "Fabian Schumacher"
format: 
  html:
    toc: true
    toc-title: Implementation of aoa.R
    html-math-method: katex
editor: visual
---

## Introduction

This markdown script describes the implementation of a quantitative-based approach to assess the Area of Applicability (*AOA*) by Meyer and Pebesma. In the current implementation of the *AOA* , for each new data point for which a prediction is to be made, only the nearest neighbor of the training samples is considered in the feature space. The distance of each new data point to the nearest neighbor of the training samples is calculated and divided by the average mean distance between all the training samples. This result is compared to a threshold to derive weather the new data point lies within the *AOA*. If the data point is smaller than the threshold, it is classified as predictable `1` and is within the *AOA*. If it is not, the point is classified as unpredictable `0` and falls out of the *AOA*. The threshold is calculated based on the training samples which is not to be addressed in this script.

The problem with this approach is that it does not provide any insight into whether one single training sample point is nearest or a new data point has several training sample points surrounding itself with same or similar distance. It could be the case that a point is classified as predictable that lies within the threshold of more than ten training samples while another that is within the threshold of only one training samples is also classified as predictable. Trivially a prediction for the first case seems more reliable. This does not imply that the prediction for the second case is not reliable, but it shows that is can be useful to have an additional approach to asses the *AOA*.

I therefore suggest implementing an additional layer `LPD` (Local Point Density) that contains the number of training data points for which a new data point is within the threshold. With this layer, it is possible for end-users to perform a more accurate assessment of the *AOA* of their model and evaluate in which areas (besides the Area of Non-Applicability) additional training data could be collected for a more reliable model prediction.

## Implementation

### Parameter `LPD` and `maxLPD`

The parameter `LPD` indicates whether the

The parameter `maxLPD` sets the number of nearest neighbors in the training samples to be considered for the `LPD`. The default value is `maxLPD = 'opt'`, which means if `maxLPD` is not set, nothing changes and the *AOA* is calculated without the additional Layer `QD`.

```{r parameter LPD and maxLPD, eval=FALSE}
aoa(
  newdata,
  model = NA,
  trainDI = NA,
  train = NULL,
  weight = NA,
  variables = "all",
  CVtest = NULL,
  CVtrain = NULL,
  method = "L2",
  useWeight = TRUE,
  LPD = FALSE,
  maxLPD = 1
)
```

#### `LPD`: (`Default value: LPD = FALSE`)

  **class** `logical`

    Allowed values: `TRUE` or `FALSE`

#### `maxLPD`: (`Default value: maxLPD = 1`)

  **class** `integer`

    Allowed values: Integer `<=` Number of training samples used for model training  

  **class** `float`

    Allowed values: 0 `<` Float `<` 1; specifies the percentage of training data used for the `LPD` calculation.

### Validate parameter `maxLPD`

This code segment validates and sets the value of the `maxLPD` parameter based on certain conditions and inputs. It's used to control the maximum number of samples for a "Local Point Density" (LPD) calculation. Depending on the conditions, it either sets maxLPD to a valid value or raises an error if the input is not valid.

1.  `calc_LPD` is assigned a value indicate whether the LPD calculation should be performed. The value are cached from `LPD` because these variables will be overwritten in a later step of the implementation with the real LPD layer. Keeping the values is important to query how the implementation should proceed at certain key points

2.  The code checks if `calc_LPD` is `TRUE`, which implies that LPD calculation is requested.

3.  If the model object inherits the class "train," it further validates maxLPD:

4.  If there's no model but `train` is not `NULL` (only training data provided), it performs similar validation for `maxLPD` with only changing how the number of training samples is derived.

```{r validation, eval=FALSE, attr.source='.numberLines startFrom="175"'}
  calc_LPD <- LPD
  # validate maxLPD input
  if (LPD == TRUE) {
    if (is.numeric(maxLPD)) {
      if (maxLPD <= 0) {
        stop("maxLPD can not be negative or equal to 0. Either define a number between 0 and 1 to use a percentage of the number of training samples for the LPD calculation or a whole number larger than 1 and smaller than the number of training samples.")
      }
      if (maxLPD <= 1) {
        if (inherits(model, "train")) {
          maxLPD <- round(maxLPD * as.integer(length(model$trainingData[[1]])))
        } else if (!is.null(train)) {
          maxLPD <- round(maxLPD * as.integer(length(train[[1]])))
        }
        if (maxLPD <= 1) {
          stop("The percentage you provided for maxLPD is too small.")
        }
      }
      if (maxLPD > 1) {
        if (maxLPD %% 1 == 0) {
          maxLPD <- as.integer(maxLPD)
        } else if (maxLPD %% 1 != 0) {
          stop("If maxLPD is bigger than 0, it should be a whole number. Either define a number between 0 and 1 to use a percentage of the number of training samples for the LPD calculation or a whole number larger than 1 and smaller than the number of training samples.")
        }
      }
      if ((maxLPD > length(if (inherits(model, "train")) { model$trainingData[[1]] } else if (!is.null(train)) { train[[1]] })) || maxLPD %% 1 != 0) {
        stop("maxLPD can not be bigger than the number of training samples. Either define a number between 0 and 1 to use a percentage of the number of training samples for the LPD calculation or a whole number larger than 1 and smaller than the number of training samples.")
      }
    } else {
      stop("maxLPD must be a number. Either define a number between 0 and 1 to use a percentage of the number of training samples for the LPD calculation or a whole number larger than 1 and smaller than the number of training samples.")
    }
  }

```

### Set optimal `maxLPD` from training data and CV

This code segment calculates the `trainDI` object. Within this procedure the Dissimilarity Index of the training data (`trainDI$trainDI`) and the Local Point Density of the training data (`trainDI$trainLPD`) are calculated.

Inside the `trainDI` function the average `LPD` is calculated for every sample depending on the cross-validation folds. That means for each cross validation iteration the samples from the test fold are considered and it is calculated for how many points from the training fold they are within the threshold. In general it would be always best to calculate the `LPD` by considering all samples in the training data. Because this can be very time consuming, depending on the size of the data you want to make a prediction for, choosing specific `maxLPD` or a percentage can help saving time with still having a good overview for which areas relatively little similar training data has been incorporated.

After calculating the `trainDI` object, it checks if `calc_LPD` is `TRUE`. If these conditions are met, it assigns the value of `trainDI$maxLPD` to the `maxLPD` variable.

```{r maxLPD from traning data, eval=FALSE, attr.source='.numberLines startFrom="224"'}

# if not provided, compute trainDI object
  if(!inherits(trainDI, "trainDI")) {
    message("No trainDI provided.")
    trainDI <- trainDI(model, train, variables, weight, CVtest, CVtrain, method, useWeight, LPD)
  }

  if (calc_LPD == TRUE) {
    # maxLPD <- trainDI$avrgLPD
    trainDI$maxLPD <- maxLPD
  }

```

### Distance Calculation

This code calculates the Dissimilarity Index (*DI*) and the Local Data Point Density (*LPD*, if `calc_LPD == TRUE`) based on the distances between new data points and training data points. For calculating the *DI* of the new data only the nearest neighbor in the training data is needed (`.mindistfun`). Calculating the *LPD* of the new data needs the distances to the k-nearest-neighbors (`.knndistfun`), where k is determined by the `maxLPD` value. For each new data point, it is counted for how many training samples it is within the threshold calculated in trainDI (`trainDI$threshold`). The resulting count values are stored in the `LPD_out` variable.

Overall, this code performs distance calculations and computes `DI_out` and `LPD_out` based on the provided parameters and data. It also ensures that `maxLPD` does not exceed the actual maximum `realMaxLPD`.

The method for distance calculation can be either *Euclidean distance* (`"L2"`) or *Mahalanobis distance* (`"MD"`), depending on the specified method. The resulting *DI* values are stored in the `DI_out` variable.

```{r distance calculation, eval=FALSE, attr.source='.numberLines startFrom="309"'}
# Distance Calculation ---------
okrows <- which(apply(newdata, 1, function(x)
  all(!is.na(x))))
newdataCC <- newdata[okrows, ]

if (method == "MD") {
  if (dim(train_scaled)[2] == 1) {
    S <- matrix(stats::var(train_scaled), 1, 1)
    newdataCC <- as.matrix(newdataCC, ncol = 1)
  } else {
    S <- stats::cov(train_scaled)
  }
  S_inv <- MASS::ginv(S)
}

if (calc_LPD == FALSE) {
  mindist <- rep(NA, nrow(newdata))
  mindist[okrows] <-
    .mindistfun(newdataCC, train_scaled, method, S_inv)
  DI_out <- mindist / trainDI$trainDist_avrgmean
}

if (calc_LPD == TRUE) {
  message("Computing LPD of newdata...")

  knndist <- matrix(NA, nrow(newdata), maxLPD)
  knndist[okrows,] <- .knndistfun(newdataCC, train_scaled, method, S_inv, maxLPD = maxLPD)

  DI_out_knndist <- knndist / trainDI$trainDist_avrgmean
  DI_out <- c(DI_out_knndist[,1])

  count_list <-
    apply(DI_out_knndist, 1, function(row)
      sum(row < trainDI$threshold))

  LPD_out <- count_list

  # set maxLPD to max of LPD_out if (maxLPD == 'max') or (maxLPD > realMaxLPD)
  realMaxLPD <- max(LPD_out, na.rm = T)
  if (maxLPD > realMaxLPD) {
    maxLPD <- realMaxLPD
    trainDI$maxLPD <- realMaxLPD
    if (inherits(method_LPD, c("numeric", "integer"))) {
      message("Your specified maxLPD was bigger than the real maxLPD of you predictor data.")
    }
    message(paste("maxLPD was set to", realMaxLPD))
  }
}
```

### Set the `LPD` layer

In this code segment the *AOA* is generated based on the calculated Dissimilarity Index (`DI`) values. It creates the *AOA* object where the values indicate whether a data point falls within the model's Area of Applicability (`1`) or outside of it (`0`). The code handles different raster formats and provides flexibility for generating `AOA` in different scenarios. If a `calc_LPD == TRUE` is specified the `LPD` layer is set additionally.

```{r set LPD layer, eval=FALSE, attr.source='.numberLines startFrom="362"'}

if (inherits(out, "SpatRaster")) {
  terra::values(out) <- DI_out

  AOA <- out
  terra::values(AOA) <- 1
  AOA[out > trainDI$thres] <- 0
  AOA <- terra::mask(AOA, out)
  names(AOA) = "AOA"

  if (calc_LPD == TRUE) {
    LPD <- out
    terra::values(LPD) <- LPD_out
    names(LPD) = "LPD"
  }


  # handling of different raster formats.
  if (as_stars) {
    out <- stars::st_as_stars(out)
    AOA <- stars::st_as_stars(AOA)

    if (calc_LPD == TRUE) {
      LPD <- stars::st_as_stars(LPD)
    }
  }

} else{
  out <- DI_out
  AOA <- rep(1, length(out))
  AOA[out > trainDI$thres] <- 0

  if (calc_LPD == TRUE) {
    LPD <- LPD_out
  }
}


if (calc_LPD == FALSE) {
  result <- list(
    parameters = trainDI,
    DI = out,
    AOA = AOA
  )
} else {
  result <- list(
    parameters = trainDI,
    DI = out,
    AOA = AOA,
    LPD = LPD
  )
}

class(result) <- "aoa"
return(result)
```

### Helper function `.knndistfun`

This function provides a way to calculate the distances between the points in a given point dataset and a set of reference points using either *Euclidean Distance* or *Mahalanobis Distance*, based on the specified method. It's particularly useful for k-nearest neighbor calculations in your code. The function returns a `n x k` matrix, with n being the number of points in the point dataset. Each row of the matrix holds the ordered distances to the k-nearest-neighbors in the reference dataset.

```{r knndistfun, eval=FALSE, attr.source='.numberLines startFrom="361"'}
.knndistfun <-
  function (point,
            reference,
            method,
            S_inv = NULL,
            k = k,
            pb = pb) {
    
    if (method == "L2") {
      # Euclidean Distance
      return(FNN::knnx.dist(reference, point, k = k))
    } else if (method == "MD") {
      # Mahalanobis Distance
      message("Calculating Mahalanobis Distance Matrix...")
      
      num_points <- dim(point)[1]
      num_reference <- dim(reference)[1]
      
      pb <- txtProgressBar(min = 0,
                           max = num_points,
                           style = 3)
      
      distances <- matrix(NA, nrow = num_points, ncol = k)
      
      for (y in 1:num_points) {
        dist_vector <- numeric(num_reference)
        
        for (x in 1:num_reference) {
          diff <- point[y,] - reference[x,]
          dist_vector[x] <- sqrt(t(diff) %*% S_inv %*% diff)
        }
        
        sorted_indices <- order(dist_vector)
        distances[y,] <- dist_vector[sorted_indices[1:k]]
        setTxtProgressBar(pb, y)
      }
      close(pb)
      return(distances)
    }
  }
```
